---
layout:     post
title:      nndl_机器学习概述
subtitle:   
date:       2018-10-16
author:     Frank
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 读书笔记
---

# 机器学习笔记



> 机器学习三要素：模型，学习准则（目标函数），优化算法



## 模型

一个机器学习任务要先需要确定其输入空间X 和输出空间Y。不同机器学 习任务的主要区别在于输出空间不同。在两类分类问题中Y = {+1, −1}，在C 类分类问题中Y = {1, 2, · · · , C}，而在回归问题中Y = R。 这里，输入空间默认为 样本的特征空间。 输入空间 X 和输出空间 Y 构成了一个样本空间。对于样本空间中的样本 (x, y) ∈ X × Y，假定存在一个未知的真实映射函数g : X → Y 使得 y = g(x), (2.5) 或者真实条件概率分布 pr(y|x), (2.6) 机器学习的目标是找到一个模型来近似真实映射函数g(x)或真实条件概率分布 pr(y|x)。

 ![1539696073807](E:\blog\loooo139.github.io\img\1539696073807.png)

## 学习准则

为了解决过拟合的问题，常用的方法就是引入参数的正则化，限制模型的能力，不要过度最小化经验风险，追求结构风险最小化。

正则化项也可以使用其它函数，比如ℓ1 范数。ℓ1 范数的引入通常会使得参 数有一定稀疏性，因此在很多算法中也经常使用。在贝叶斯学习的角度来讲，则化是假设了参数的先验分布，不完全依赖训练数据。 

## 优化算法

在确定训练集D，假设空间$$f$$，以及学习准则之后，其转化为一个最优化问题。

**参数和超参数**， 在机器学习中，优化又可以分为参数优化和超参数优化。模型 f(x, θ)中的θ 称为模型的参数，可以通过优化算法进行学习。除了可学习的参 数θ 之外，还有一类参数是用来定义模型结构或优化策略的，这类参数叫做超 参数（hyper-parameter）。  

常见的超参数包括：聚类算法中的类别个数、梯度下降法的步长、正则项 的系数、神经网络的层数、支持向量机中的核函数等。超参数的选取一般都是 组合优化问题，很难通过优化算法来自动学习。因此，超参数优化是机器学习 的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对 一组超参数组合进行不断试错调整。 



最小二乘法要求各个特征之间相互独立，保证XX^T可逆。但在实际的应用中，特征之间可能会有很大的共线性，即XX T 的值可能接近零，会导致最小二乘法估计的计算变得不稳定。为了解决这个问题，提出了岭回归，给XXt的对角线元素加一个常数。岭回归的解w∗ 可以看做是结构风险最小化准则下的最小二乘法估计。 R(w) = 1 2 ∥y − XTw∥ 2 + 1 2 λ∥w∥ 2 , 